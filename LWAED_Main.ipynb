{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-12 04:05:47.289394: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-12 04:05:47.937964: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, UpSampling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-12 04:05:56.794199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22319 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:a1:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "# Create Autoencoder\n",
    "def LWAED(image_size, gray=False):\n",
    "    kernel_size = 3  # (3, 3)\n",
    "    pooling_size = 2  # (2, 2)\n",
    "\n",
    "    image_shape = np.concatenate((image_size, [1] if gray else [3]))\n",
    "    with strategy.scope():\n",
    "        model = Sequential()\n",
    "\n",
    "        # Input layer\n",
    "        model.add(Input(shape=image_shape))\n",
    "\n",
    "        #########\n",
    "        # Encoder\n",
    "        # Conv\n",
    "        model.add(Conv2D(50, kernel_size=kernel_size, activation='relu', padding='same'))\n",
    "        model.add(AveragePooling2D(pooling_size, padding='same'))\n",
    "        model.add(Conv2D(50, kernel_size=kernel_size, activation='relu', padding='same'))\n",
    "        model.add(AveragePooling2D(pooling_size, padding='same'))\n",
    "        # Dense\n",
    "        model.add(Dense(10))\n",
    "\n",
    "        # Decoder\n",
    "        # Dense\n",
    "        model.add(Dense(10))\n",
    "        # Conv\n",
    "        model.add(Conv2D(50, kernel_size=kernel_size, activation='relu', padding='same'))\n",
    "        model.add(UpSampling2D(pooling_size))\n",
    "        model.add(Conv2D(50, kernel_size=kernel_size, activation='relu', padding='same'))\n",
    "        model.add(UpSampling2D(pooling_size))\n",
    "\n",
    "        # Output layer\n",
    "        # model.add(Conv2D(3, kernel_size=kernel_size, activation='sigmoid', padding='same'))\n",
    "        model.add(Conv2D(3, kernel_size=kernel_size, activation='relu', padding='same'))\n",
    "\n",
    "        opt = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "        model.compile(optimizer=opt, loss='mse')\n",
    "        model.build()\n",
    "        model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "def resizer_function(image_paths, size=(360, 640)):\n",
    "    num_images = len(image_paths)\n",
    "    data = np.empty((num_images, size[1], size[0], 3), dtype=np.float32)\n",
    "\n",
    "    for i, image_path in tqdm(enumerate(image_paths), total=num_images):\n",
    "        img = np.array((Image.open(image_path).convert('RGB').resize(size, Image.LANCZOS)), dtype=np.float32)\n",
    "        img /= 255.0 \n",
    "        data[i] = img\n",
    "\n",
    "    return data\n",
    "\n",
    "def load_images_with_glob(directory, size, max_images=None):\n",
    "    image_paths = glob.glob(os.path.join(directory, \"*.jpg\"))  \n",
    "    image_paths.sort()\n",
    "    if max_images is not None:\n",
    "        image_paths = image_paths[:max_images]\n",
    "    return image_paths\n",
    "\n",
    "\n",
    "image_size = (640, 360)\n",
    "max_images = 39000\n",
    "\n",
    "dataset_path1 = '/media/hdd/aryan/ifseg3/Dataset/NEW_MASK_2.0'\n",
    "dataset_path2 = '/media/hdd/aryan/ifseg3/Dataset/TRAIN_CUSTOM'\n",
    "\n",
    "# Load X and y, Normalized \n",
    "x = load_images_with_glob(dataset_path1, image_size, max_images)\n",
    "y = load_images_with_glob(dataset_path2, image_size, max_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (360, 640)\n",
    "with strategy.scope():\n",
    "    model = LWAED(image_size=image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 26\n",
    "num_batches = len(x) // batch_size\n",
    "\n",
    "\n",
    "for i in tqdm(range(num_batches), desc=\"Training Batches\"):\n",
    "    print(\"BATCH : \", i)\n",
    "    \n",
    "    start_idx = i * batch_size\n",
    "    end_idx = (i + 1) * batch_size if i < num_batches - 1 else len(x)\n",
    "    \n",
    "    print(\"start_idx, end_idx : \", start_idx, end_idx)\n",
    "    image_size = (640, 360)\n",
    "    x_images = resizer_function(x[start_idx:end_idx], image_size)\n",
    "    y_images = resizer_function(y[start_idx:end_idx], image_size)\n",
    "    \n",
    "    with tf.device('/device:GPU:0'):\n",
    "        x_batch = tf.convert_to_tensor(x_images[0:19]) \n",
    "    with tf.device('/device:GPU:0'):\n",
    "        y_batch = tf.convert_to_tensor(y_images[0:19])\n",
    "    \n",
    "    # Train the model on the current batch\n",
    "    history = model.fit(x_batch, y_batch, validation_split=0.1, epochs=200, batch_size=batch_size, verbose=0)\n",
    "    train_loss_values = history.history['loss']\n",
    "    val_loss_values = history.history['val_loss']\n",
    "    average_train_loss = sum(train_loss_values) / len(train_loss_values)\n",
    "    average_val_loss = sum(val_loss_values) / len(val_loss_values)\n",
    "    print(f\"Average Validation Loss: {average_val_loss:.6f} \" + f\"Average Training Loss: {average_train_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('LCA_weight/LCA_640.360_78k.keras')\n",
    "model.save('LCA_weight/LCA_640.360_78k.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_size = (360, 640)\n",
    "test_image_path = '/home/aryan/sih23/Dataset/MASK_CUSTOM/38342.jpg'  \n",
    "\n",
    "# Load and preprocess the test image\n",
    "test_image = load_img(test_image_path, target_size=image_size)\n",
    "test_image = img_to_array(test_image)\n",
    "test_image = test_image / 255.0  \n",
    "\n",
    "# Reshape the test image to match the model's input shape\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "\n",
    "# Use the model to make predictions\n",
    "predicted_image = model.predict(test_image)\n",
    "predicted_image = np.clip(predicted_image, 0.0, 1.0)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 7))\n",
    "original_image = load_img(test_image_path, target_size=image_size)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Original Image')\n",
    "plt.imshow(original_image)\n",
    "\n",
    "\n",
    "predicted_image = predicted_image[0]  \n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Predicted Image')\n",
    "plt.imshow(predicted_image)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
